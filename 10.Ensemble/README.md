  #  综述

集成学习， 等价于多算法的融合， 或者说高级的投票机制。

   # 主要两大类

Boosting算法： 个体模型之间存在强依赖关系，串行生成。

Bagging算法： 个体模型之间不存在强依赖关系，可以同时生成。

   # Boosting算法

是一种常见的统计学习方法。 代表为Adaboost 算法， 是一种通过改变权值使弱学习变成强学习的算法。

   # Bagging算法

自主采样法，代表为随即森林。 Random Forest。

# 实战代码：GitHub：

1. Adaboost classifier

https://github.com/JasonK93/ML-note/blob/master/10.Ensemble/10.1%20Adaboost%20classifer.py

2. Adaboost regression

https://github.com/JasonK93/ML-note/blob/master/10.Ensemble/10.2%20adaboost%20regression.py

3. RF_ classifier

https://github.com/JasonK93/ML-note/blob/master/10.Ensemble/10.3%20RF_classifier.py

4.RF_ regression

https://github.com/JasonK93/ML-note/blob/master/10.Ensemble/10.4%20RF_regression.py

5. Gradient_ Classifer

https://github.com/JasonK93/ML-note/blob/master/10.Ensemble/10.5%20Gradient_Classifier.py

6. Gradient _ Regression

https://github.com/JasonK93/ML-note/blob/master/10.Ensemble/10.6%20Gradient_regresion.py



